{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "987ef6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --upgrade git+https://github.com/huggingface/diffusers.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ba7d33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --upgrade transformers accelerate scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cc7500e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --upgrade torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2471bc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install diffusers transformers accelerate safetensors omegaconf invisible-watermark>=0.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2caff2dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "text_encoder\\model.safetensors not found\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aa61c6bcdb943e4b3f3437494662528",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from diffusers import StableDiffusionPipeline, EulerDiscreteScheduler\n",
    "import torch\n",
    "\n",
    "model_id = \"stabilityai/stable-diffusion-2\"\n",
    "\n",
    "scheduler = EulerDiscreteScheduler.from_pretrained(model_id, subfolder=\"scheduler\")\n",
    "pipe = StableDiffusionPipeline.from_pretrained(model_id, scheduler=scheduler, torch_dtype=torch.float16)\n",
    "pipe = pipe.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c358063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f81a734dfdd4ac69fa2bf41a78ceca3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRed car\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mimages[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      4\u001b[0m image\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\diffusers\\pipelines\\stable_diffusion\\pipeline_stable_diffusion.py:723\u001b[0m, in \u001b[0;36mStableDiffusionPipeline.__call__\u001b[1;34m(self, prompt, height, width, num_inference_steps, guidance_scale, negative_prompt, num_images_per_prompt, eta, generator, latents, prompt_embeds, negative_prompt_embeds, output_type, return_dict, callback, callback_steps, cross_attention_kwargs, guidance_rescale, clip_skip)\u001b[0m\n\u001b[0;32m    720\u001b[0m     noise_pred \u001b[38;5;241m=\u001b[39m rescale_noise_cfg(noise_pred, noise_pred_text, guidance_rescale\u001b[38;5;241m=\u001b[39mguidance_rescale)\n\u001b[0;32m    722\u001b[0m \u001b[38;5;66;03m# compute the previous noisy sample x_t -> x_t-1\u001b[39;00m\n\u001b[1;32m--> 723\u001b[0m latents \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscheduler\u001b[38;5;241m.\u001b[39mstep(noise_pred, t, latents, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mextra_step_kwargs, return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    725\u001b[0m \u001b[38;5;66;03m# call the callback, if provided\u001b[39;00m\n\u001b[0;32m    726\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(timesteps) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m ((i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m>\u001b[39m num_warmup_steps \u001b[38;5;129;01mand\u001b[39;00m (i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscheduler\u001b[38;5;241m.\u001b[39morder \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\diffusers\\schedulers\\scheduling_euler_discrete.py:397\u001b[0m, in \u001b[0;36mEulerDiscreteScheduler.step\u001b[1;34m(self, model_output, timestep, sample, s_churn, s_tmin, s_tmax, s_noise, generator, return_dict)\u001b[0m\n\u001b[0;32m    393\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_step_index(timestep)\n\u001b[0;32m    395\u001b[0m sigma \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigmas[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_index]\n\u001b[1;32m--> 397\u001b[0m gamma \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(s_churn \u001b[38;5;241m/\u001b[39m (\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msigmas\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m s_tmin \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m sigma \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m s_tmax \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m    399\u001b[0m noise \u001b[38;5;241m=\u001b[39m randn_tensor(\n\u001b[0;32m    400\u001b[0m     model_output\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39mmodel_output\u001b[38;5;241m.\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mmodel_output\u001b[38;5;241m.\u001b[39mdevice, generator\u001b[38;5;241m=\u001b[39mgenerator\n\u001b[0;32m    401\u001b[0m )\n\u001b[0;32m    403\u001b[0m eps \u001b[38;5;241m=\u001b[39m noise \u001b[38;5;241m*\u001b[39m s_noise\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\_tensor.py:904\u001b[0m, in \u001b[0;36mTensor.__len__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;21m__neg__\u001b[39m \u001b[38;5;241m=\u001b[39m _C\u001b[38;5;241m.\u001b[39m_TensorBase\u001b[38;5;241m.\u001b[39mneg\n\u001b[0;32m    902\u001b[0m \u001b[38;5;21m__abs__\u001b[39m \u001b[38;5;241m=\u001b[39m _C\u001b[38;5;241m.\u001b[39m_TensorBase\u001b[38;5;241m.\u001b[39mabs\n\u001b[1;32m--> 904\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__len__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    905\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    906\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__len__\u001b[39m, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "prompt = \"Red car\"\n",
    "image = pipe(prompt).images[0]\n",
    "    \n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f87d156",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
